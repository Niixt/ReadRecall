{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c454dcbc",
   "metadata": {},
   "source": [
    "# Draft notebook for the application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bb043",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275c2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b959801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a6110",
   "metadata": {},
   "source": [
    "## Test book content loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cd821b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loaders.book_content_loader as bcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8325f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"Martin Eden\"\n",
    "res_search = bcl.search_books(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f84b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_archive = bcl.get_book_archive_page(res_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68337543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book found with length: 930190 characters\n",
      " named,  and  which  you  say  yourself  are \n",
      "good  —  you  have  not  sold  any  of  them.  We  can’t  get \n",
      "married  on  masterpieces  that  won’t  sell.” \n",
      "\n",
      "“  Then  we’ll  get  married  on  triolets\n"
     ]
    }
   ],
   "source": [
    "book_text = bcl.fetch_book_text(url_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41060f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "LIGATURES = {\n",
    "    \"ﬀ\": \"ff\", \"ﬁ\": \"fi\", \"ﬂ\": \"fl\", \"ﬃ\": \"ffi\", \"ﬄ\": \"ffl\", \"ﬅ\": \"ft\", \"ﬆ\": \"st\"\n",
    "}\n",
    "\n",
    "def normalize_unicode(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    for lig, repl in LIGATURES.items():\n",
    "        text = text.replace(lig, repl)\n",
    "    # normalize different dashes and quotes\n",
    "    text = text.replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \" - \").replace(\"\\u00AC\", \"-\")\n",
    "    text = text.replace(\"\\u2018\", \"'\").replace(\"\\u2019\", \"'\").replace(\"\\u201c\", '\"').replace(\"\\u201d\", '\"')\n",
    "    # remove weird non-breaking spaces\n",
    "    text = text.replace(\"\\u00A0\", \" \")\n",
    "    return text\n",
    "\n",
    "def remove_uc_only_lines(text: str) -> str:\n",
    "    # heuristics: many header/footer lines are ALL CAPS short words (publisher, title)\n",
    "    lines = text.splitlines()\n",
    "    out = []\n",
    "    for ln in lines:\n",
    "        ln_stripped = ln.strip()\n",
    "        if not ln_stripped:\n",
    "            out.append(ln)\n",
    "            continue\n",
    "        # if line is short and mostly uppercase and not a sentence, drop it\n",
    "        if len(ln_stripped) < 60:\n",
    "            alpha_chars = re.sub(r'[^A-Za-z]', '', ln_stripped)\n",
    "            if alpha_chars and alpha_chars.upper() == alpha_chars and len(alpha_chars) > 3:\n",
    "                # avoid deleting lines that look like sentences (end with . ? !)\n",
    "                if not re.search(r'[.?!]\\s*$', ln_stripped) and 'chapter' not in ln_stripped.lower():\n",
    "                    # skip likely header/footer\n",
    "                    continue\n",
    "        out.append(ln)\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def remove_page_numbers(text: str) -> str:\n",
    "    # Remove lines that are only numbers or numbers with small decorations\n",
    "    lines = text.splitlines()\n",
    "    newlines = []\n",
    "    for ln in lines:\n",
    "        if re.fullmatch(r'\\s*\\d+\\s*', ln):\n",
    "            continue\n",
    "        # also remove lines like \"Page 12\" (common)\n",
    "        if re.fullmatch(r'\\s*(page|pg|p\\.)\\s*\\d+\\s*', ln, flags=re.IGNORECASE):\n",
    "            continue\n",
    "        newlines.append(ln)\n",
    "    return \"\\n\".join(newlines)\n",
    "\n",
    "def fix_hyphenation(text: str) -> str:\n",
    "    # merge words split with hyphen at EOL:\n",
    "    # pattern: 'hy- \\nphenated' or 'hy-\\nphenated' -> 'hyphenated'\n",
    "    text = re.sub(r'([A-Za-z])-\\n([A-Za-z])', r'\\1\\2', text)\n",
    "    # also handle hyphen + spaces + newline\n",
    "    text = re.sub(r'([A-Za-z])-\\s*\\n\\s*([A-Za-z])', r'\\1\\2', text)\n",
    "    return text\n",
    "\n",
    "def reflow_paragraphs(text: str) -> str:\n",
    "    # Reflow lines within paragraphs: paragraphs separated by empty lines.\n",
    "    parts = re.split(r'\\n{2,}', text)\n",
    "    reflowed = []\n",
    "    for p in parts:\n",
    "        # strip leading/trailing spaces per paragraph\n",
    "        lines = [ln.strip() for ln in p.splitlines() if ln.strip()]\n",
    "        if not lines:\n",
    "            reflowed.append(\"\")\n",
    "            continue\n",
    "        # join with single space\n",
    "        joined = \" \".join(lines)\n",
    "        # collapse multiple spaces\n",
    "        joined = re.sub(r'\\s+', ' ', joined).strip()\n",
    "        reflowed.append(joined)\n",
    "    return \"\\n\".join(reflowed)\n",
    "\n",
    "def dedupe_repeated_header_footer(text: str, page_break_token: str = None) -> str:\n",
    "    # If you have a page break token (like '\\f') use it. Otherwise guess by rough pages.\n",
    "    if page_break_token and page_break_token in text:\n",
    "        pages = text.split(page_break_token)\n",
    "    else:\n",
    "        # attempt naive page split if the source used form feed markers, else split by approx page length\n",
    "        approx_chars = 3000\n",
    "        pages = [text[i:i+approx_chars] for i in range(0, len(text), approx_chars)]\n",
    "    header_cands = Counter()\n",
    "    footer_cands = Counter()\n",
    "    first_lines = []\n",
    "    last_lines = []\n",
    "    for p in pages:\n",
    "        lines = [ln.strip() for ln in p.splitlines() if ln.strip()]\n",
    "        if not lines:\n",
    "            continue\n",
    "        first_lines.append(lines[0][:120])\n",
    "        last_lines.append(lines[-1][:120])\n",
    "    # find frequent first/last lines\n",
    "    for ln in first_lines:\n",
    "        header_cands[ln] += 1\n",
    "    for ln in last_lines:\n",
    "        footer_cands[ln] += 1\n",
    "    # choose candidates that appear on many pages (threshold)\n",
    "    n_pages = max(1, len(pages))\n",
    "    headers = {ln for ln, c in header_cands.items() if c > max(1, n_pages*0.4)}\n",
    "    footers = {ln for ln, c in footer_cands.items() if c > max(1, n_pages*0.4)}\n",
    "    # remove these exact lines from the text\n",
    "    if headers or footers:\n",
    "        def drop_headers_footers_line(ln):\n",
    "            s = ln.strip()\n",
    "            if s in headers or s in footers:\n",
    "                return False\n",
    "            return True\n",
    "        out_lines = [ln for ln in text.splitlines() if drop_headers_footers_line(ln)]\n",
    "        return \"\\n\".join(out_lines)\n",
    "    return text\n",
    "\n",
    "def collapse_whitespace(text: str) -> str:\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    # normalize repeated blank lines to two newlines for paragraph separation\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_book_text(raw: str, page_break_token: str = None) -> str:\n",
    "    t = raw\n",
    "    t = normalize_unicode(t)\n",
    "    t = dedupe_repeated_header_footer(t, page_break_token=page_break_token)\n",
    "    t = remove_page_numbers(t)\n",
    "    t = remove_uc_only_lines(t)\n",
    "    t = fix_hyphenation(t)\n",
    "    t = reflow_paragraphs(t)\n",
    "    t = collapse_whitespace(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab54dd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930190\n"
     ]
    }
   ],
   "source": [
    "print(len(book_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e72f32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw = open('documents/Martin_Eden_raw.txt', 'r', encoding='utf-8').read()\n",
    "cleaned = clean_book_text(book_text, page_break_token='\\f')  # pass '\\f' if present\n",
    "open('documents/Martin_Eden_clean.txt', 'w', encoding='utf-8').write(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5699750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shed back into the canvas. \" A trick picture,\" was his thought, as he dismissed it, though in the mi'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[5000:5100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a1e753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me  a  fighting  light.  He  looked  about \\nmore  unconcernedly,  sharply  observant,  every  detail'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(book_text))\n",
    "\n",
    "book_text[5000:5100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed17ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book text written to documents/Martin_Eden.txt\n"
     ]
    }
   ],
   "source": [
    "path_book_content = bcl.write_book_to_file(book_text, search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f3a19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'documents/Martin_Eden.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_book_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554c1c2",
   "metadata": {},
   "source": [
    "## RAG with HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f704ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import retrieval.rag_retriever as rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "baf2e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cut_at_end_token(text: str, end_token: str = \"END\") -> str:\n",
    "    # If the model included the end marker, keep everything before it.\n",
    "    idx = text.find(\"\\n\" + end_token)\n",
    "    if idx == -1:\n",
    "        idx = text.find(end_token)\n",
    "    if idx != -1:\n",
    "        return text[:idx].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def remove_trailing_questions(text: str) -> str:\n",
    "    # Split into sentences, remove trailing sentences that are questions or look like follow-ups.\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    if not sentences:\n",
    "        return text\n",
    "    # Walk backward and drop trailing sentences that end with '?' or begin with interrogative words\n",
    "    interrogatives = r'^(would|could|should|do|did|are|is|what|why|how|when|where|who)\\b'\n",
    "    cut_index = len(sentences)\n",
    "    for i in range(len(sentences) - 1, -1, -1):\n",
    "        s = sentences[i].strip()\n",
    "        if not s:\n",
    "            cut_index = i\n",
    "            continue\n",
    "        if s.endswith('?') or re.match(interrogatives, s.lower()):\n",
    "            cut_index = i\n",
    "            continue\n",
    "        # stop at first non-question-like sentence\n",
    "        break\n",
    "    cleaned = ' '.join(sentences[:cut_index]).strip()\n",
    "    return cleaned if cleaned else text\n",
    "\n",
    "def finalize_model_output(raw: str) -> str:\n",
    "    # 1) Prefer strict END marker\n",
    "    res = cut_at_end_token(raw, end_token=\"END\")\n",
    "    # 2) If the END token wasn't present or text still ends with questions, remove trailing questions\n",
    "    res = remove_trailing_questions(res)\n",
    "    # 3) Optional: collapse whitespace\n",
    "    return re.sub(r'\\s+', ' ', res).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b08834ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1411 document chunks\n",
      "Vector store created (persist_directory=chroma_db), vectors=1411\n",
      "Loading model: Qwen/Qwen3-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG system initialized successfully!\n",
      "\n",
      "Question: Who is Ruth?\n",
      "\n",
      "Answer:  1) A young girl from New England who lived during World War II; 2) An artist whose life has been devoted to painting portraits as part of her career; 3) A person living on the edge of society, struggling against economic hardship due to war-related issues;\n",
      "4) A romantic figure who loves poetry but also struggles with personal insecurities related to being perceived as inferior;\n",
      "\n",
      "The correct answers must include exactly four options listed above. Also, each option corresponds directly to one trait mentioned in the text. If multiple choices can apply, select them accordingly.\n",
      "**\n",
      "**\n",
      "\n",
      "Here's my final answer:\n",
      "\n",
      "Ruth is described as a young girl... [insert first point]\n",
      "\n",
      "[...]\n",
      "\n",
      "[Ruth] lives on the edge...\n",
      "\n",
      "[I am sorry, I need to provide three different attributes.]\n",
      "\n",
      "Okay, let me check again. The context says:\n",
      "\n",
      "\"She was stung...\" so maybe Option 1? But wait, looking back, the initial statement said \"This is Ms.\" instead of Mrs., so perhaps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RAG system\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\" if torch.cuda.is_available() else \"Qwen/Qwen3-0.6B\" # \"HuggingFaceTB/SmolLM2-135M\"\n",
    "rag = rr.LocalRAGSystem(\"documents/Martin_Eden_clean.txt\",\n",
    "                        model_name=model_name,\n",
    "                        model_name_embeddings=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "answer_tag = \"**Answer:**\"\n",
    "\n",
    "# Example query\n",
    "result = rag.query(\"Who is Ruth?\")\n",
    "\n",
    "# raw_answer = result.get(\"result\") or result.get(\"answer\") or \"\"\n",
    "# clean = finalize_model_output(raw_answer)\n",
    "# result[\"result_clean\"] = clean\n",
    "\n",
    "print(f\"\\nQuestion: {result['query']}\")\n",
    "print(\"\\nAnswer:\", result[\"result\"][result[\"result\"].find(answer_tag) + len(answer_tag):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ed774c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='doc_10', metadata={'source': 'documents/Martin_Eden_clean.txt'}, page_content=\"He glanced around at his friend reading the letter and saw the books on the table. Into his eyes leaped a wistfulness and a yearning as promptly as the yearning leaps into the eyes of a starving man at sight of food. An impulsive stride, with one lurch to right and left of the shoulders, brought him to the table, where he began affectionately handling the books. He glanced at the titles and the authors' names, read fragments of text, caressing the volumes with his eyes and hands, and, once, recognized a book he had read. For the rest, they were strange bocks and strange authors. He chanced upon a volume of Swinburne and began reading steadily, forgetful of where he was, his face glowing. Twice he closed the book on his forefinger to look at the name of the author. Swinburne ! he would\"),\n",
       " Document(id='doc_11', metadata={'source': 'documents/Martin_Eden_clean.txt'}, page_content=\"forgetful of where he was, his face glowing. Twice he closed the book on his forefinger to look at the name of the author. Swinburne ! he would remember that name. That fellow had eyes, and he had certainly seen color and flashing light. But who was Swinburne? Was he dead a hundred years or so, like most of the poets ? Or was he alive still, and writing ? He turned to the title-page . . . yes, he had written other books ; well, he would go to the free library the first thing in the morning and try to get hold of some of Swinburne's stuff. He went back to the text and lost himself. He did not notice that a young woman had entered the room. The first he knew was when he heard Arthur's voice saying: -\")]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.vectorstore.get_by_ids([\"doc_10\", \"doc_11\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44437b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\" Ruth, this is Mr. Eden.\"' metadata={'source': 'documents/Martin_Eden_clean.txt'}\n",
      "page_content='She was stung by his words into realization of the puerility of her act, and yet she felt that he had magnified it unduly and was consequently resentful. They sat in silence for a long time, she thinking desperately and he pondering upon his love which had departed. He knew, now, that he had not really loved her. It was an idealized Ruth he had loved, an ethereal creature of his own creating, the bright and luminous spirit of his lovepoems. The real bourgeois Ruth, with all the bourgeois failings and with the hopeless cramp of the bourgeois psychology in her mind, he had never loved.\n",
      "She suddenly began to speak.' metadata={'source': 'documents/Martin_Eden_clean.txt'}\n",
      "page_content='\" Then you did like the other women ? \"\n",
      "He shook his head.\n",
      "\" That social-settlement woman is no more than a sociological poll-parrot. I swear, if you winnowed her out between the stars, like Tomlinson, there would be found in her not one original thought. As for the portraitpainter, she was a positive bore. She'd make a good wife for the cashier. And the musician woman! I don't care how nimble her fingers are, how perfect her technique, how wonderful her expression - the fact is, she knows nothing about music.\"\n",
      "\" She plays beautifully,\" Ruth protested.' metadata={'source': 'documents/Martin_Eden_clean.txt'}\n"
     ]
    }
   ],
   "source": [
    "for i in result['source_documents']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015230a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Chroma' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__version__\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'Chroma' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readrecall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
